{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Výběr snímků z videa\n",
    "mit video moc rychle\n",
    "## Focus measure\n",
    "[https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/]\n",
    "\n",
    "Nejkvalitnější snímky z videa jsou ty s nejmenším rozmazáním. Méně rozmazaný snímek zároven zřejmě bude mít výraznější hrany než ten více rozmazaný. Hrany detekujeme pomocí konvoluce Laplaceova operátoru s vybraným snímkem. Výsledný (absolutní) průměr této matice nám bude sloužit jako nástroj k porovnávání rozmazání mezi snímky.\n",
    "Tato metoda není úplně přesná, protože se scéna na snímcích konstantě mění, nicméně se nemění tak dramaticky, aby nebyla použitelná.\n",
    "\n",
    "## Velikost okna\n",
    "Předpokládáme rychlost kamery 20 cm/s a frame rate 30FPS ,tedy posun 2/3 cm/frame.\n",
    "Chceme aby se dva snímky překrývali alespon ze 1/3 (při menším překryvu by počítání tr.mat mohlo být obtížné/nepřesné) a zároven se nepřerývali více než ze 1/2 (minimalizace počtu snímků).\n",
    "Předpokládáme, že snímek zobrazuje vertikálně 1 m ve skutečnosti. Pak se dostáváme na hodnotu okna 37-75 framů.\n",
    "\n",
    "Nápad : Počítání rychlosti kamery. 2 kola\n",
    "1) Vyberu dostatečně ostré snímky (jen na začátku/ celé video?). Možná budu potřebovat pevné okno? \n",
    "\n",
    "2) Spočítám si projektivní tr. matice.\n",
    "\n",
    "3) Pomocí velikosti posunu tr.matice a časovou vzdáleností spočítám průměrnou rychlost.\n",
    "\n",
    "4) Přes známou rychlost spočítám přesnější okno\n",
    "\n",
    "100 frameu uprostred-spocitam rychlost z toho\n",
    "dynamicke zvetsivano/zmensovani okna podle predchoziho-lepsi\n",
    "\n",
    "## Error threshold\n",
    "\n",
    "Pro odhad dobré transformace použijeme následující metodu: Označíme smer. odchylku intenzity snímku jako errThresh. Tato hodnota nám bude sloužit jako prah při porovnávání s chybou transformace. Ta je spočítána jako sum(abs(I1-I2)) kde I1,I2 jsou překrývající se části snímků.\n",
    "Pokud se chyba žádného snímku nevejde pod ErrThresh, je vybrán snímek s nejmenší chybou transformace v daném okně.\n",
    "\n",
    "mean     = sum(x)/length(x)\n",
    "variance = sum((x - mean(x)).^2)/(length(x) - 1);\n",
    "std = sqrt(variance)\n",
    "\n",
    "\n",
    "## Pipeline\n",
    "Pro všechny snímky ve videu je spočítána focus measure. Všechny ostatní práce se snímky je postupně dělána ve vyhrazených oknech, což je soubor snímků vzdálený od předchozího vybraného snímku minimální a maximální vzáleností(vzdáleností je myšleno časové pořadí snímků). Pro první průchod je jednoduše vybrán snímek s největší fm a spočítán ErrThresh pomocí něj. Zbytek cyklu probíhá takto:\n",
    "\n",
    "1) Všechny snímky okna jsou v sestupném pořadí seřazeny podle jejich focus measure.\n",
    "\n",
    "2) Snímky jsou jeden po druhém registrovány na vybraný snímek z předchozího okna, dokun není nalezen snímek s chybou transformace menší než ErrThresh. Pokud ani jeden není menší, je vybrán snímek s nejmenší chybout tr.\n",
    "\n",
    "3) Tento snímek je přidán do konečného výběru snímků "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registrace panoramatu\n",
    "[https://www.mathworks.com/help/vision/ug/feature-based-panoramic-image-stitching.html]\n",
    "\n",
    "## computeTforms\n",
    "Transfromační matice jsou počítány následující způsobem:\n",
    "Snímek je převeden do černobílý (1 vrstva místo 3 u RGB) a jsou naněm detekovány body pomocí SURF detektoru. Z těchto bodů jsou vybrány příznaky, které jsou následně spárovány s příznaky z předchozího snímku.\n",
    "Tyto 2 seznamy jsou poté použity funkcí estimateGeometricTransform, která spočítá odpovídající tr. matici.\n",
    "Pro potřeby panoramatu je použita affiní transformace, protože u projektivní dochází při součinu matic ke velké chybě.\n",
    "\n",
    "Pokud chceme, aby referenčním snímkem v panoramatu byl jiný než první, je potřeba je přepočítat pomocí \n",
    "tforms(j).T = tforms(j).T * Tinv.T; kde Tinv je inverze ref. snímku.\n",
    "\n",
    "## computeLimits\n",
    "Je třeba znát rozměry výsledného panoramatu, čehož docílíme transformací 4 bodů okrajů u všech snímku a následným výběrem těch nejzaších. V tomto kroce je dobré ověřit velikost pro výsledné panorama, pokud je příliš velká, evidentně někde nastala chyba.\n",
    "\n",
    "## createPanorama\n",
    "Díky znalosti rozměrů panoramatu si můžeme vytvořit konečný souřadný systém, do kterého nejdříve vložíme masku (opět 4 kraje původního snímku) a následně do místa masky vložíme transformovaný snímek. (Masku pak můžeme využít na zobrazení vizualizaci poskládání všech snímků)\n",
    "\n",
    "## Omezení \n",
    "Jak bylo výše uvedeno, u dlouhých panoramat s jakými pracujeme my, je třeba použít affiní, či podobnostní transformaci, nebot při součinu projektivních transformací dochází ke stále větší a větší chybě, a při více než 5-7 snímcích ani nelze žádné panorama vytvořit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeatability rate\n",
    "\n",
    "[https://hal.inria.fr/inria-00548302/document]\n",
    "\n",
    "Repeatability rate definujeme jako počet stejných bodů vyskytujících se na obou snímcích vzhledem k celkovém počtu detekovaných bodů. Z detekovaných bodů vybíráme pouze ty, které jsou součástí scény vyskytujících se na obou snímcích.\n",
    "\n",
    "![repeat](aaa.png)\n",
    "\n",
    "Je důležité vzít v úvahu nepřesnost detekce. Korespondující bod se nebude nacházet přesně daném místě určeném maticí, ale v jeho $\\epsilon$-okolí. $\\epsilon$-reapeatabilitu definujeme jako R<sub>i</sub>($\\epsilon$) = {(x<sub>i</sub>,x<sub>j</sub>)|dist(H<sub>ij</sub>x<sub>i</sub>, x<sub>j</sub>) < $\\epsilon$}\n",
    "\n",
    "Počet detekovaných bodů ve společné části snímku nebude stejný, proto vybereme menší z nich, abychom zajistili existenci bodu z $\\epsilon$-reapeatability. Repeatability rate je tedy definováno následovně:\n",
    " r<sub>i</sub>($\\epsilon$)=abs(R<sub>i</sub>($\\epsilon$))/min(n<sub>i</sub>,<sub>j</sub>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vliv rozmazání na registraci\n",
    "\n",
    "Pro sledování vlivu rozmazání na kvalitu registrace použijeme dvojice sousedících snímků, které uměle rozmažeme aplikací motion-blur filtru náhodné orientace v rozsahu <0,190> a pevně zvolené délky v rozsahu <1,50>, kdy je postupně přidávana po inkrementech 5(pixelů?). Z jedné dvojice tak získáme 11 (12 s originálními) párů rozmazaných snímků. U nich pak najdeme příznaky, namatchujeme je a odhadneme homografní matici. Pro E v Eps-repeatabilite dosadíme 10. Takte získáme repeatability rate.\n",
    "\n",
    "\n",
    "Dále chceme znát localization error, tedy průměrnou vzdálenost bodu predikovaného tr. maticí od místa, kde se bod skutečně nachází. To se dá vyjádřit jako:\n",
    "dist(i) =  norm(p2(i,:)-predicted(i,:)); mean(dist)\n",
    "\n",
    "Takto projdeme celý daný set snímků. Tady je graf setu 1:\n",
    "![title](rep.png)\n",
    "Na vertikální ose je repeatability rate a jeho rozptyl, na horizontální délka filtru. Jak lze vidět z grafu, do cca 30 pixelu je kvalita registrace poměrně spolehlivá, pak ale začne rychle klesat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vliv artefaktů\n",
    "\n",
    "Sledování vlivu zmenšování datového toku kvalitu registrace.\n",
    "Plánovaný postup:\n",
    "\n",
    "1)Vygeneruju set videí se různým datovým tokem\n",
    "\n",
    "2)Problém s výběrem snímku (od nějakého to už nezvládne vybrat snímek)\n",
    "\n",
    "   řešení: vybírám předem dané snímky (znám čísla z originálu)\n",
    "    \n",
    "3)Dále postup stejný jako u bluru (detekce příznaků, matching, estimateGeometricTransform,etc...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sčítání cenovek\n",
    "\n",
    "V této části si ukážeme využití výše zmíněných metod na problému počítání cenovek. V podstatě jde o schopnost detekce stejného objektu na více snímcích a následném rozdělění tak, aby každý snímek měl \"své\" cenovky. Pro toto je využití vlastností transfromačních matic ideální.\n",
    "\n",
    "Pro samotnou detekci cenovek byla využita typ síte YOLOv5[https://github.com/ultralytics/yolov5] natrénována na cenovky od firmy DataSentics.\n",
    "Ta vyniká především pro svou rychlost i malou velikost, čímž je vhodná pro využití v mobilních zařízeních.\n",
    "Vstupem je snímek a výstupem list souřadnic bounding boxů.\n",
    "\n",
    "Snímky jsou získany z videa postupem výše uvedeném. Mezi těmito snímky je spočítany matice projektivní transformace a je také (odděleně) vygenerováno panorama pomocí affiní transformace. Toto panoram slouží k ručnímu\n",
    "sčítání cenovek.\n",
    "\n",
    "V každém cyklu jsou vzaty 3 po sobě jsoucí snímky, v nichž jsou následně detekovány cenovky. První a třetí bboxy jsou převedeny transformací do souřadného systému druhého snímku. Poté jsou přes Python knihovnu Shapely[] souřadnice bboxů převedeny do polygonů pro snadnější manipulaci. \n",
    "\n",
    "Polygony prvního a druhého snímku jsou dávány přes sebe a pokud je nalezen překryv, polygon je odstraněn z list ve 3. a zůstává pouze ve 1.\n",
    "Následně jsou podobným způsoben kontrolovány polygony 1.&2. a 3.&2. Při nalezení překryvu ale o tom, ze kterého listu bude polygon smazán rozhoduje velikost obsahu cenovky.\n",
    "\n",
    "Po prvním cyklu neprochází již detekované snímky sítí znovu, místo toho jsou brány seznamy z předchozích 2 cyklů.\n",
    "Díky tomu nedochází k duplikaci cenovek na různých snímcích. Mohlo by v nějakých případech dojít k duplikaci, pokud by se objekt objevil na 4 a více snímcích po sobě, nicméně k tomu v podstatě nedochází, vzhledem k tomu že snímky jsou vybrány z videa, tak, aby neměly tak velký překryv. Nehledě na to, že při součinu projektivních transformačních matic se rychle kumuluje chyba po několika cyklech by se bboxy přestaly překrývat.\n",
    "\n",
    "\n",
    "## Omezení\n",
    "Sít má problém s cenovkami velmi blízko u sebe a najde neexistující cenovky. Také má problém správně detekovat cenovky vyloženě přes sebe a neobvyklých formátů(elektronické, moc dlouhé)\n",
    "\n",
    "## Výsledky\n",
    "ručně/program\n",
    "\n",
    "set30-188/190\n",
    "\n",
    "set34-102/96\n",
    "\n",
    "mít 5 setů - vizualizace pomocí panoramatu s cenovkami přes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
